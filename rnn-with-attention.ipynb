{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11879398,"sourceType":"datasetVersion","datasetId":7465773},{"sourceId":11896049,"sourceType":"datasetVersion","datasetId":7477707}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installing required dependencies required for the assignment\n\n!pip install lightning -qU\n!pip install wandb -qU","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:17:56.791565Z","iopub.execute_input":"2025-05-21T11:17:56.791853Z","iopub.status.idle":"2025-05-21T11:20:09.166412Z","shell.execute_reply.started":"2025-05-21T11:17:56.791800Z","shell.execute_reply":"2025-05-21T11:20:09.165455Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Importing necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport torch \nfrom torch import nn\n\nimport lightning as L\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport wandb\n\nfrom lightning.pytorch.loggers import WandbLogger\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:09.170217Z","iopub.execute_input":"2025-05-21T11:20:09.170414Z","iopub.status.idle":"2025-05-21T11:20:29.235679Z","shell.execute_reply.started":"2025-05-21T11:20:09.170390Z","shell.execute_reply":"2025-05-21T11:20:29.234871Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Using Wandb API key, login to wandb account\nfrom kaggle_secrets import UserSecretsClient\napi_key = UserSecretsClient().get_secret(\"wandb_api\")\n\nwandb.login(key=api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:29.237023Z","iopub.execute_input":"2025-05-21T11:20:29.237471Z","iopub.status.idle":"2025-05-21T11:20:35.529129Z","shell.execute_reply.started":"2025-05-21T11:20:29.237452Z","shell.execute_reply":"2025-05-21T11:20:35.528541Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohitrk06\u001b[0m (\u001b[33mrohitrk06-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#Since Kaggle is used to train the model, we have upload the data at this address.\n#In case you are excuting the code, make sure that you have correct directory path of the dataset\ndataset_path = \"/kaggle/input/dakshina-dataset-v1-0-hi/dakshina_dataset_v1.0_hi/lexicons\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:38.068841Z","iopub.execute_input":"2025-05-21T11:20:38.069571Z","iopub.status.idle":"2025-05-21T11:20:38.073211Z","shell.execute_reply.started":"2025-05-21T11:20:38.069547Z","shell.execute_reply":"2025-05-21T11:20:38.072619Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Creating a custom dataset class in pytorch to store the transliteration dataset.\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, dataframe, source_vocab, target_vocab):\n        self.dataframe = dataframe\n        self.source_vocab = source_vocab\n        self.target_vocab = target_vocab\n\n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        src_words = [ self.source_vocab[chr] if chr in self.source_vocab else self.source_vocab[\"<UNK>\"] for chr in self.dataframe.iloc[idx][\"source\"]]\n\n        # Similarly, for the target words        \n        tgt_words = [self.target_vocab[chr] if chr in self.target_vocab else self.target_vocab[\"<UNK>\"] for chr in self.dataframe.iloc[idx][\"target\"]]\n        # Add <SOW> and <EOW> tokens to the target words\n        tgt_words = [self.target_vocab[\"<SOW>\"]] + tgt_words + [self.target_vocab[\"<EOW>\"]]\n\n        return torch.LongTensor(src_words), torch.LongTensor(tgt_words) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:38.763965Z","iopub.execute_input":"2025-05-21T11:20:38.764230Z","iopub.status.idle":"2025-05-21T11:20:38.769802Z","shell.execute_reply.started":"2025-05-21T11:20:38.764211Z","shell.execute_reply":"2025-05-21T11:20:38.769138Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#Since we are using lightning module, Let's define the Lightning data module to handle the dataset\nclass TrasnliterationDataModule(L.LightningDataModule):\n    def __init__(self, data_dir, batch_size=32):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n\n        \n        # Load the train dataset\n        self.train_df = pd.read_csv(\n            f\"{self.data_dir}/hi.translit.sampled.train.tsv\",\n            sep=\"\\t\",\n            names=[\"target\", \"source\", \"attestations\"],\n            header=None,\n            keep_default_na=False, na_values=[]\n        )\n        # Drop the attestations column\n        self.train_df.drop(columns=[\"attestations\"], inplace=True)\n\n        # Let's load the dev set as well\n        # We will use the dev set for validation\n        self.dev_df = pd.read_csv(\n            f\"{self.data_dir}/hi.translit.sampled.dev.tsv\",\n            sep=\"\\t\",\n            names=[\"target\", \"source\", \"attestations\"],\n            header=None,\n            keep_default_na=False, na_values=[]\n        )\n        # Drop the attestations column\n        self.dev_df.drop(columns=[\"attestations\"], inplace=True)\n\n\n        #Let's load the test set as well\n        # We will use the test set for evaluation\n        self.test_df = pd.read_csv(\n            f\"{self.data_dir}/hi.translit.sampled.test.tsv\",\n            sep=\"\\t\",\n            names=[\"target\", \"source\", \"attestations\"],\n            header=None,\n            keep_default_na=False, na_values=[]\n        )\n        # Drop the attestations column\n        self.test_df.drop(columns=[\"attestations\"], inplace=True)\n\n        # Create vocabularies for source and target languages\n        self.source_vocab, self.source_chr_to_idx, self.source_idx_to_char = self.build_vocab(self.train_df['source'].values)\n        self.target_vocab, self.target_chr_to_idx, self.target_idx_to_char = self.build_vocab(self.train_df['target'].values)\n\n\n    def prepare_data(self):\n        '''\n        According the the Lightning documentation, this method is used to download and prepare the data.\n        In our case, we are not downloading any data, dataset can be found at the given data_dir path, but we are preparing the data\n        '''\n        \n        self.train_dataset = self.create_dataset(self.train_df)\n        self.dev_dataset = self.create_dataset(self.dev_df)\n        self.test_dataset = self.create_dataset(self.test_df)\n\n    def build_vocab(self, words):\n        '''\n        This method is used to build the vocab for the given data\n        :param data: The data to build the vocab for\n        :return: The vocab for the given data\n        '''\n        vocab = set()\n        for word in words:\n            for char in word:\n                vocab.add(char)\n\n        # Adding special tokens in the vocab.\n        vocab.add(\"<UNK>\")\n        vocab.add(\"<EOW>\")\n        vocab.add(\"<SOW>\")\n\n        # Sort the vocab to get the same order every time\n        vocab = sorted(vocab)\n        \n        chr_to_idx_map = { chr : idx+1 for idx, chr in enumerate(vocab) }\n        idx_to_chr_map = { idx+1 : chr for idx, chr in enumerate(vocab) }\n\n        chr_to_idx_map[\"<PAD>\"] = 0\n        idx_to_chr_map[0] = \"<PAD>\"\n\n        vocab.append(\"<PAD>\")\n        \n        return vocab, chr_to_idx_map, idx_to_chr_map\n\n    def create_dataset(self, dataframe):\n        '''\n        This method is used to create the dataset for the given data\n        :param dataframe: The dataframe to create the dataset for\n        :return: The dataset for the given data\n        '''\n        return TransliterationDataset(dataframe, self.source_chr_to_idx, self.target_chr_to_idx)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size = self.batch_size, shuffle=True, collate_fn = self.collate_fn, num_workers=3)\n    \n    def val_dataloader(self):\n        return DataLoader(self.dev_dataset, batch_size = self.batch_size, shuffle=False, collate_fn = self.collate_fn, num_workers=3)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size = self.batch_size, shuffle=False, collate_fn = self.collate_fn, num_workers=3)\n    \n    def collate_fn(self, batch):\n        '''\n        This method is used to collate the data into batches\n        :param batch: The batch to collate\n        :return: The collated batch\n        '''\n        src_words, tgt_words = zip(*batch)\n        \n        # Pad the source and target words\n        src_words = torch.nn.utils.rnn.pad_sequence(src_words, batch_first=True, padding_value=0)\n        tgt_words = torch.nn.utils.rnn.pad_sequence(tgt_words, batch_first=True, padding_value=0)\n\n        return src_words, tgt_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:40.675779Z","iopub.execute_input":"2025-05-21T11:20:40.676088Z","iopub.status.idle":"2025-05-21T11:20:40.691402Z","shell.execute_reply.started":"2025-05-21T11:20:40.676067Z","shell.execute_reply":"2025-05-21T11:20:40.690773Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#In the below cells,we would define the encoder, decoder architecture, \n\nclass Encoder(nn.Module):\n    def __init__(self, cell_type, input_embedding_size, embedding_dimension, hidden_layer_size, num_layers, dropout):\n        super(Encoder, self).__init__()\n        self.hidden_layer_size = hidden_layer_size\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        # Embedding layer\n        self.embedding = nn.Embedding(input_embedding_size, embedding_dimension, padding_idx=0)\n\n        # Here while defining the embedding layer, we have set the padding_idx to 0, which is the index of the <PAD> token in our vocab.\n        # This means that the embedding layer will ignore the padding tokens when computing the embeddings.\n        # The embedding layer will learn the embeddings for the input characters.\n\n        # Encoder RNN cell\n        self.rnn_cell = {\n            \"RNN\": nn.RNN,\n            \"LSTM\": nn.LSTM,\n            \"GRU\": nn.GRU\n        }.get(cell_type)\n        if self.rnn_cell is None:\n            raise ValueError(\"Invalid cell type. Choose 'RNN', 'LSTM' or 'GRU'.\")\n        self.rnn = self.rnn_cell(embedding_dimension, hidden_layer_size, num_layers, dropout=dropout, batch_first=True)\n\n    def forward(self, x):\n        input = self.embedding(x)\n        output, hidden = self.rnn(input)\n        return output, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:44.420268Z","iopub.execute_input":"2025-05-21T11:20:44.420952Z","iopub.status.idle":"2025-05-21T11:20:44.426553Z","shell.execute_reply.started":"2025-05-21T11:20:44.420928Z","shell.execute_reply":"2025-05-21T11:20:44.425740Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class AttentionModule(nn.Module):\n    def __init__(self, hidden_size):\n        super(AttentionModule, self).__init__()\n        self.attn = nn.Linear(hidden_size*2,hidden_size)\n        self.v = nn.Linear(hidden_size,1,bias=False)\n\n    def forward(self,decoder_hidden,encoder_outputs, mask=None):\n        #Here, dimension of decoder_hidden = (batch, 1, hidden)\n        # dimension of encoder_outputs: (batch, src_len, hidden)\n        src_len = encoder_outputs.size(1)\n        decoder_hidden  = decoder_hidden.repeat(1,src_len,1) # this will make the dimension: (batch, src_len, hidden)\n\n        energy = torch.tanh(self.attn(torch.cat((decoder_hidden,encoder_outputs), dim = 2)))\n        attention = self.v(energy).squeeze(2)\n        if mask is not None:\n            attention = attention.masked_fill(mask == 0, torch.finfo(attention.dtype).min)\n        return F.softmax(attention,dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:46.705886Z","iopub.execute_input":"2025-05-21T11:20:46.706154Z","iopub.status.idle":"2025-05-21T11:20:46.712113Z","shell.execute_reply.started":"2025-05-21T11:20:46.706135Z","shell.execute_reply":"2025-05-21T11:20:46.711310Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, cell_type, output_embedding_size, embedding_dimension, hidden_layer_size, num_layers, dropout):\n        super(Decoder, self).__init__()\n        # Embedding layer\n        self.embedding = nn.Embedding(output_embedding_size, embedding_dimension, padding_idx=0)\n\n        rnn_cell = {\n            \"RNN\": nn.RNN,\n            \"LSTM\": nn.LSTM,\n            \"GRU\": nn.GRU\n        }.get(cell_type)\n        if rnn_cell is None:\n            raise ValueError(\"Invalid cell type. Choose 'RNN', 'LSTM' or 'GRU'.\")\n        \n        self.rnn = rnn_cell(embedding_dimension + hidden_layer_size, hidden_layer_size, num_layers, dropout=dropout, batch_first=True)\n\n        # Output layer\n        self.fc = nn.Linear(hidden_layer_size * 2, output_embedding_size)\n\n        #attention module\n        self.attention = AttentionModule(hidden_layer_size)\n        self.cell_type = cell_type\n        \n    def forward(self, x, hidden, encoder_outputs, mask = None):\n        embedded = self.embedding(x)\n\n        if self.cell_type == \"LSTM\":\n            dec_hidden = hidden[0][-1].unsqueeze(1)\n        else:\n            dec_hidden = hidden[-1].unsqueeze(1)\n\n        attn_weights = self.attention(dec_hidden, encoder_outputs, mask).unsqueeze(1)\n\n        context = torch.bmm(attn_weights, encoder_outputs)\n\n        rnn_input = torch.cat((embedded, context), dim = 2)\n\n        output, hidden = self.rnn(rnn_input, hidden)\n        output = output.squeeze(1)\n        context = context.squeeze(1)\n\n        output = self.fc(torch.cat((output,context),dim=1))\n                \n        return output.unsqueeze(1), hidden, attn_weights.squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:47.805024Z","iopub.execute_input":"2025-05-21T11:20:47.805294Z","iopub.status.idle":"2025-05-21T11:20:47.812356Z","shell.execute_reply.started":"2025-05-21T11:20:47.805273Z","shell.execute_reply":"2025-05-21T11:20:47.811778Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Seq2Seq(L.LightningModule):\n    def __init__(self, input_embedding_size, output_embedding_size, embedding_dimension, \n                 hidden_layer_size, number_of_layers_encoder, number_of_layers_decoder, \n                 dropout, cell_type, learning_rate, teacher_forcing_ratio=0.5):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Initialize encoder and decoder\n        self.encoder = Encoder(cell_type, input_embedding_size, embedding_dimension,\n                              hidden_layer_size, number_of_layers_encoder, dropout)\n        self.decoder = Decoder(cell_type, output_embedding_size, embedding_dimension,\n                              hidden_layer_size, number_of_layers_decoder, dropout)\n        \n        # Loss function ignoring padding\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n        self.learning_rate = learning_rate\n        self.teacher_forcing_ratio = teacher_forcing_ratio\n\n    def forward(self, src, tgt, teacher_forcing_ratio=None):\n        batch_size, tgt_len = tgt.size()\n        outputs = torch.zeros(batch_size, tgt_len-1, self.hparams.output_embedding_size)\n\n        attn_weights_all = []\n        # Encoder forward\n        encoder_outputs, hidden = self.encoder(src)\n        \n        # Initialize decoder hidden state\n        if self.hparams.cell_type == 'LSTM':\n            decoder_hidden = (hidden[0][:self.hparams.number_of_layers_decoder],\n                             hidden[1][:self.hparams.number_of_layers_decoder])\n        else:\n            decoder_hidden = hidden[:self.hparams.number_of_layers_decoder]\n        \n        decoder_input = tgt[:, 0].unsqueeze(1)  # Start with SOS token\n        mask = (src!=0)\n        # Decoder forward\n        for t in range(tgt_len-1):\n            decoder_output, decoder_hidden, attn_weights = self.decoder(decoder_input, decoder_hidden, encoder_outputs, mask)\n            outputs[:, t] = decoder_output.squeeze(1)\n            attn_weights_all.append(attn_weights.detach().cpu())\n            # Teacher forcing\n            tf_ratio = self.teacher_forcing_ratio if teacher_forcing_ratio is None else teacher_forcing_ratio\n            teacher_force = torch.rand(1).item() < tf_ratio\n            top1 = decoder_output.argmax(2)\n            decoder_input = tgt[:, t+1].unsqueeze(1) if teacher_force else top1\n\n        attn_weights_all = torch.stack(attn_weights_all, dim=1)\n        return outputs, attn_weights_all\n\n    def __shared_step(self, batch, batch_idx, stage):\n        src, tgt = batch\n        output,_ = self(src, tgt, teacher_forcing_ratio=0 if stage != 'train' else None)\n        tgt = tgt.to(output.device)\n        loss = self.criterion(output.reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n        self.log(f\"{stage}_loss\", loss)\n        \n        # Calculate metrics\n        preds = output.argmax(2)\n        non_pad = tgt[:, 1:] != 0\n        correct = (preds == tgt[:, 1:]) & non_pad\n        \n        # Token-level accuracy\n        token_acc = correct.sum().float() / non_pad.sum()\n        self.log(f\"{stage}_token_acc\", token_acc, prog_bar=True)\n        \n        # Sequence-level accuracy\n        seq_acc = ((preds == tgt[:, 1:]) | ~non_pad).all(dim=1).float().mean()\n        self.log(f\"{stage}_seq_acc\", seq_acc, prog_bar=True)\n        \n        return loss\n\n    def training_step(self, batch, batch_idx):\n        return self.__shared_step(batch, batch_idx, \"train\")\n\n    def validation_step(self, batch, batch_idx):\n        return self.__shared_step(batch, batch_idx, \"val\")\n\n    def test_step(self, batch, batch_idx):\n        return self.__shared_step(batch, batch_idx, \"test\")\n\n    def predict_step(self, batch, batch_idx):\n        src, _ = batch  # Don't require target during prediction\n        output,_ = self(src, torch.zeros_like(src), teacher_forcing_ratio=0)\n        return output.argmax(2)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:49.950699Z","iopub.execute_input":"2025-05-21T11:20:49.951512Z","iopub.status.idle":"2025-05-21T11:20:49.963127Z","shell.execute_reply.started":"2025-05-21T11:20:49.951477Z","shell.execute_reply":"2025-05-21T11:20:49.962583Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def create_sweep_name(config):\n    return (f\"{config.cell_type}_\"\n            f\"encoder_nl_{config.num_layers}_\"\n            f\"decoder_nl_{config.num_layers}_\"\n            f\"embedd_dim_{config.embedd_dim}_\"\n            f\"hidden_size_{config.hidden_size}\"\n            f\"tf_ratio_{config.teacher_force_ratio}_\"\n            f\"lr_{config.lr}_\"\n            f\"dropout_{config.dropout}_\"\n            f\"max_epoches_{config.max_epochs}_\"\n            f\"batch_size_{config.batch_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:20:00.321070Z","iopub.execute_input":"2025-05-20T15:20:00.321335Z","iopub.status.idle":"2025-05-20T15:20:00.337925Z","shell.execute_reply.started":"2025-05-20T15:20:00.321309Z","shell.execute_reply":"2025-05-20T15:20:00.337318Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def main(config = None):\n    wandb.init(project = \"da6401_assignment3_v1\",\n               config = config)\n    config = wandb.config\n    wandb.run.name = create_sweep_name(config)\n\n    wandb_logger = WandbLogger(project = \"da6401_assignment3_v1\",\n                               log_model = True)\n\n    data = TrasnliterationDataModule(dataset_path,batch_size = config.batch_size)\n    \n    \n    model = Seq2Seq(len(data.source_vocab), len(data.target_vocab),embedding_dimension = config.embedd_dim,\n                   hidden_layer_size = config.hidden_size, number_of_layers_encoder=config.num_layers, number_of_layers_decoder=config.num_layers, \n                     dropout=config.dropout, cell_type= config.cell_type, learning_rate=config.lr, teacher_forcing_ratio=config.teacher_force_ratio)\n    # model = torch.compile(model)\n\n    trainer = L.Trainer(\n        logger = wandb_logger,\n        # strategy='ddp_spawn',\n        max_epochs = config.max_epochs,\n        precision=\"16-mixed\",\n        # devices = 2,\n    )\n\n    trainer.fit(model, data) \n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:33:24.348112Z","iopub.execute_input":"2025-05-20T09:33:24.348714Z","iopub.status.idle":"2025-05-20T09:33:24.353952Z","shell.execute_reply.started":"2025-05-20T09:33:24.348690Z","shell.execute_reply":"2025-05-20T09:33:24.353262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    \"name\": \"Hyperparameter Sweep for different rnn cells with attention\",\n    \"method\": \"bayes\",\n    \"metric\": {\n        \"name\": \"val_loss\",\n        \"goal\": \"minimize\"\n    },\n    \"parameters\": {\n        \"embedd_dim\": {\n            \"values\": [128, 256, 512]\n        },\n        \"hidden_size\": {\n            \"values\": [128, 256, 512]\n        },\n        \"num_layers\": {\n            \"values\": [3, 5]\n        },\n        \"dropout\": {\n            \"values\": [0.3,0.4]\n        },\n        \"teacher_force_ratio\": {\n            \"values\": [0.1, 0.3, 0.5]\n        },\n        \"cell_type\": {\n            \"values\": [\"LSTM\"]\n        },\n        \"max_epochs\":{\n            \"values\":[10,15]\n        },\n        \"lr\": {\n            \"distribution\": \"log_uniform_values\",\n            \"min\": 1e-4,\n            \"max\": 1e-3\n        },\n        \"batch_size\":{\n            \"values\":[64,128,256]\n        }\n    },\n    \"early_terminate\": {\n        \"type\": \"hyperband\",\n        \"min_iter\": 3,\n        \"max_iter\": 20,\n        \"eta\": 2\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:34:56.877208Z","iopub.execute_input":"2025-05-20T09:34:56.877942Z","iopub.status.idle":"2025-05-20T09:34:56.883536Z","shell.execute_reply.started":"2025-05-20T09:34:56.877917Z","shell.execute_reply":"2025-05-20T09:34:56.882722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config,project=\"da6401_assignment3_v1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:36:46.165864Z","iopub.execute_input":"2025-05-20T09:36:46.166630Z","iopub.status.idle":"2025-05-20T09:36:46.590366Z","shell.execute_reply.started":"2025-05-20T09:36:46.166606Z","shell.execute_reply":"2025-05-20T09:36:46.589639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.agent(sweep_id,main,count=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:47:15.224090Z","iopub.execute_input":"2025-05-20T09:47:15.224693Z","iopub.status.idle":"2025-05-20T09:50:29.976576Z","shell.execute_reply.started":"2025-05-20T09:47:15.224668Z","shell.execute_reply":"2025-05-20T09:50:29.975629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After performing a hyperparameter sweep, \n# Let's use the best hyperparameters to train the model and evaluate the model on the test set.\nbatch_size = 128\nembbed_dim = 512\nhidden_size = 512\nnum_layers = 3\ndropout = 0.4\ncell_type = \"RNN\"\nlr = 0.000417\nteacher_force_ratio = 0.5\nmax_epochs = 15\n\ndata = TrasnliterationDataModule(dataset_path,batch_size = batch_size)\nmodel = Seq2Seq(len(data.source_vocab), len(data.target_vocab), embedding_dimension = embbed_dim,\n               hidden_layer_size= hidden_size, number_of_layers_encoder = num_layers,number_of_layers_decoder=num_layers, \n                     dropout=dropout, cell_type= cell_type, learning_rate=lr, teacher_forcing_ratio=teacher_force_ratio)\n\nwandb_logger = WandbLogger(project = \"da6401_assignment3\",\n                               log_model = True)\n\ntrainer = L.Trainer(\n    logger = wandb_logger,\n    # strategy='ddp_spawn',\n    max_epochs = max_epochs,\n    precision=\"16-mixed\",\n    # devices = 2,\n)\ntrainer.fit(model, data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:20:56.865161Z","iopub.execute_input":"2025-05-21T11:20:56.865457Z","iopub.status.idle":"2025-05-21T11:27:14.018506Z","shell.execute_reply.started":"2025-05-21T11:20:56.865437Z","shell.execute_reply":"2025-05-21T11:27:14.017705Z"}},"outputs":[{"name":"stderr","text":"INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20250521_112057-vd8xppcp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3/runs/vd8xppcp' target=\"_blank\">swift-voice-162</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3/runs/vd8xppcp' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3/runs/vd8xppcp</a>"},"metadata":{}},{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name      | Type             | Params | Mode \n-------------------------------------------------------\n0 | encoder   | Encoder          | 1.6 M  | train\n1 | decoder   | Decoder          | 2.5 M  | train\n2 | criterion | CrossEntropyLoss | 0      | train\n-------------------------------------------------------\n4.1 M     Trainable params\n0         Non-trainable params\n4.1 M     Total params\n16.231    Total estimated model params size (MB)\n11        Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de86294ec1584e89861a3c662d7b4ead"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=15` reached.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"trainer.test(model,data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:27:14.020129Z","iopub.execute_input":"2025-05-21T11:27:14.020357Z","iopub.status.idle":"2025-05-21T11:27:15.294756Z","shell.execute_reply.started":"2025-05-21T11:27:14.020337Z","shell.execute_reply":"2025-05-21T11:27:15.294155Z"}},"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4207fe02c4394a21b436a8dd34b7d609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9642021059989929    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m      test_seq_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4033762812614441    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m     test_token_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.746080219745636    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9642021059989929     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seq_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4033762812614441     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">      test_token_acc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.746080219745636     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'test_loss': 0.9642021059989929,\n  'test_token_acc': 0.746080219745636,\n  'test_seq_acc': 0.4033762812614441}]"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# After performing a hyperparameter sweep, \n# Let's use the best hyperparameters to train the model and evaluate the model on the test set.\nbatch_size = 128\nembbed_dim = 512\nhidden_size = 512\nnum_layers = 3\ndropout = 0.3\ncell_type = \"LSTM\"\nlr = 0.00094\nteacher_force_ratio = 0.5\nmax_epochs = 15\n\ndata = TrasnliterationDataModule(dataset_path,batch_size = batch_size)\nmodel = Seq2Seq(len(data.source_vocab), len(data.target_vocab), embedding_dimension = embbed_dim,\n               hidden_layer_size= hidden_size, number_of_layers_encoder = num_layers,number_of_layers_decoder=num_layers, \n                     dropout=dropout, cell_type= cell_type, learning_rate=lr, teacher_forcing_ratio=teacher_force_ratio)\n\nwandb_logger = WandbLogger(project = \"da6401_assignment3\",\n                               log_model = True)\n\ntrainer = L.Trainer(\n    logger = wandb_logger,\n    # strategy='ddp_spawn',\n    max_epochs = max_epochs,\n    precision=\"16-mixed\",\n    # devices = 2,\n)\ntrainer.fit(model, data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:32:26.269586Z","iopub.execute_input":"2025-05-21T11:32:26.270244Z","iopub.status.idle":"2025-05-21T11:39:56.615898Z","shell.execute_reply.started":"2025-05-21T11:32:26.270217Z","shell.execute_reply":"2025-05-21T11:39:56.615133Z"}},"outputs":[{"name":"stderr","text":"INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\nINFO: Using 16bit Automatic Mixed Precision (AMP)\nINFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n/usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory ./da6401_assignment3/vd8xppcp/checkpoints exists and is not empty.\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name      | Type             | Params | Mode \n-------------------------------------------------------\n0 | encoder   | Encoder          | 6.3 M  | train\n1 | decoder   | Decoder          | 8.0 M  | train\n2 | criterion | CrossEntropyLoss | 0      | train\n-------------------------------------------------------\n14.3 M    Trainable params\n0         Non-trainable params\n14.3 M    Total params\n57.199    Total estimated model params size (MB)\n11        Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f157c59d1dff4821b47bfbcea4d99cbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=15` reached.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"trainer.test(model,data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:39:56.617512Z","iopub.execute_input":"2025-05-21T11:39:56.617731Z","iopub.status.idle":"2025-05-21T11:39:58.722197Z","shell.execute_reply.started":"2025-05-21T11:39:56.617711Z","shell.execute_reply":"2025-05-21T11:39:58.721140Z"}},"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"277f60db6bde466da7eaf4c8afa081a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0675084590911865    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m      test_seq_acc       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4280319809913635    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m     test_token_acc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7606055736541748    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0675084590911865     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seq_acc        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4280319809913635     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">      test_token_acc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7606055736541748     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[{'test_loss': 1.0675084590911865,\n  'test_token_acc': 0.7606055736541748,\n  'test_seq_acc': 0.4280319809913635}]"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def decode_sequence(tensor, chr2idx, idx2char):\n    chars = []\n    for idx in tensor:\n        if idx.item() in [chr2idx['<EOW>'], chr2idx['<PAD>']]:\n            break\n        chars.append(idx2char.get(idx.item(), '<UNK>'))\n    return ''.join(chars)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:43:26.763927Z","iopub.execute_input":"2025-05-21T11:43:26.764732Z","iopub.status.idle":"2025-05-21T11:43:26.770027Z","shell.execute_reply.started":"2025-05-21T11:43:26.764701Z","shell.execute_reply":"2025-05-21T11:43:26.769460Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import os\nimport random\n\n\nwandb.init(project=\"da6401_assignment3_v1\", name=\"predictions_attention\", job_type=\"test_evaluation\")\ndata.prepare_data()\ntest_dataloader = data.test_dataloader()\nmodel.eval()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Create predictions directory\nos.makedirs('predictions_attention', exist_ok=True)\n\n\n# For wandb logging\nsample_table = wandb.Table(columns=[\"Source\", \"Target\", \"Prediction\"])\n\n# Test evaluation\npredictions = []\nwith torch.no_grad(), open('predictions_attention/test_predictions_attention.csv', 'w') as f:\n    f.write(\"Source,Target,Prediction\\n\")\n    \n    for batch in test_dataloader:\n        src, tgt = batch\n        src, tgt = src.to(device), tgt.to(device)\n        outputs, _ = model(src, tgt, teacher_forcing_ratio=0)\n        preds = outputs.argmax(dim=2)\n        \n        # Decode sequences\n        for i in range(src.size(0)):\n            source_str = decode_sequence(src[i], data.source_chr_to_idx, data.source_idx_to_char)\n            target_str = decode_sequence(tgt[i][1:], data.target_chr_to_idx, data.target_idx_to_char)  # Skip <SOW>\n            pred_str = decode_sequence(preds[i],  data.target_chr_to_idx, data.target_idx_to_char)\n            \n            f.write(f'\"{source_str}\",\"{target_str}\",\"{pred_str}\"\\n')\n            predictions.append((source_str, target_str, pred_str))\n\n            # Add a few (e.g. 20) predictions to W&B table\n            if len(sample_table.data) < 40 and random.random()<0.02:\n                sample_table.add_data(source_str, target_str, pred_str)\n\n# Log the table to wandb\nwandb.log({\"Sample Test Predictions\": sample_table})\nwandb.finish()\n\nwandb.finish()\n\nprint(\"Predictions saved to predictions_attention/test_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T11:51:17.130172Z","iopub.execute_input":"2025-05-21T11:51:17.130930Z","iopub.status.idle":"2025-05-21T11:51:26.771008Z","shell.execute_reply.started":"2025-05-21T11:51:17.130903Z","shell.execute_reply":"2025-05-21T11:51:26.770212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_115117-ui1nc7mr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/ui1nc7mr' target=\"_blank\">predictions_attention</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/ui1nc7mr' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/ui1nc7mr</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">predictions_attention</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/ui1nc7mr' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/ui1nc7mr</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_115117-ui1nc7mr/logs</code>"},"metadata":{}},{"name":"stdout","text":"Predictions saved to predictions_attention/test_predictions.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\n\n# Load prediction files\nvanilla_df = pd.read_csv(\"/kaggle/input/test-predictions-vanilla/test_predictions_vanilla.csv\")\nattention_df = pd.read_csv(\"/kaggle/working/predictions_attention/test_predictions_attention.csv\")\n\n# Mark which predictions are correct\nvanilla_df[\"VanillaCorrect\"] = vanilla_df[\"Target\"] == vanilla_df[\"Prediction\"]\nattention_df[\"AttentionCorrect\"] = attention_df[\"Target\"] == attention_df[\"Prediction\"]\n\n# Merge the two DataFrames\ncombined = vanilla_df.copy()\ncombined[\"AttentionPrediction\"] = attention_df[\"Prediction\"]\ncombined[\"AttentionCorrect\"] = attention_df[\"AttentionCorrect\"]\n\n# Filter: incorrect in vanilla but correct in attention\ncorrected_cases = combined[(combined[\"VanillaCorrect\"] == False) & (combined[\"AttentionCorrect\"] == True)]\n\n\n\n# Print sample of corrections\nprint(f\"\\nTotal corrections made by attention model: {len(corrected_cases)}\\n\")\ncorrected_cases[[\"Source\", \"Target\", \"Prediction\", \"AttentionPrediction\"]].head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:03:05.856373Z","iopub.execute_input":"2025-05-21T12:03:05.856939Z","iopub.status.idle":"2025-05-21T12:03:05.893399Z","shell.execute_reply.started":"2025-05-21T12:03:05.856918Z","shell.execute_reply":"2025-05-21T12:03:05.892780Z"}},"outputs":[{"name":"stdout","text":"\nTotal corrections made by attention model: 524\n\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"              Source        Target   Prediction AttentionPrediction\n0                ank           अंक          एंक                 अंक\n2              ankit         अंकित         आंकत               अंकित\n7              ankor         अंकोर        एंकोर               अंकोर\n9            angarak        अंगारक        अंगरक              अंगारक\n23           ambaani        अंबानी       अमबानी              अंबानी\n24            ambani        अंबानी       अमबानी              अंबानी\n51             azhar          अजहर         अजार                अजहर\n53             agnat        अज्ञात       अग्ञात              अज्ञात\n59              atke          अटके          अटे                अटके\n68           atharva         अथर्व        अठर्व               अथर्व\n75         advaitwad     अद्वैतवाद   अद्वैत्वाद           अद्वैतवाद\n82       adhyayanrat      अध्ययनरत    अध्ययनर्त            अध्ययनरत\n83        adhyaynrat      अध्ययनरत    अध्ययनर्त            अध्ययनरत\n92       anaavashyak      अनावश्यक    अनावाश्यक            अनावश्यक\n93        anavashyak      अनावश्यक     अनावाशयक            अनावश्यक\n94         anavshyak      अनावश्यक      अनावशयक            अनावश्यक\n95        anawashyak      अनावश्यक     अनावाशयक            अनावश्यक\n101         anukulta      अनुकूलता     अनुकुलता            अनुकूलता\n108           anuthi         अनूठी        अनुठि               अनूठी\n116  aparivartanshil  अपरिवर्तनशील  अपरिवर्तशील        अपरिवर्तनशील","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Target</th>\n      <th>Prediction</th>\n      <th>AttentionPrediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ank</td>\n      <td>अंक</td>\n      <td>एंक</td>\n      <td>अंक</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ankit</td>\n      <td>अंकित</td>\n      <td>आंकत</td>\n      <td>अंकित</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ankor</td>\n      <td>अंकोर</td>\n      <td>एंकोर</td>\n      <td>अंकोर</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>angarak</td>\n      <td>अंगारक</td>\n      <td>अंगरक</td>\n      <td>अंगारक</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ambaani</td>\n      <td>अंबानी</td>\n      <td>अमबानी</td>\n      <td>अंबानी</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>ambani</td>\n      <td>अंबानी</td>\n      <td>अमबानी</td>\n      <td>अंबानी</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>azhar</td>\n      <td>अजहर</td>\n      <td>अजार</td>\n      <td>अजहर</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>agnat</td>\n      <td>अज्ञात</td>\n      <td>अग्ञात</td>\n      <td>अज्ञात</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>atke</td>\n      <td>अटके</td>\n      <td>अटे</td>\n      <td>अटके</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>atharva</td>\n      <td>अथर्व</td>\n      <td>अठर्व</td>\n      <td>अथर्व</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>advaitwad</td>\n      <td>अद्वैतवाद</td>\n      <td>अद्वैत्वाद</td>\n      <td>अद्वैतवाद</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>adhyayanrat</td>\n      <td>अध्ययनरत</td>\n      <td>अध्ययनर्त</td>\n      <td>अध्ययनरत</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>adhyaynrat</td>\n      <td>अध्ययनरत</td>\n      <td>अध्ययनर्त</td>\n      <td>अध्ययनरत</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>anaavashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाश्यक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>anavashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>anavshyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>anawashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>anukulta</td>\n      <td>अनुकूलता</td>\n      <td>अनुकुलता</td>\n      <td>अनुकूलता</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>anuthi</td>\n      <td>अनूठी</td>\n      <td>अनुठि</td>\n      <td>अनूठी</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>aparivartanshil</td>\n      <td>अपरिवर्तनशील</td>\n      <td>अपरिवर्तशील</td>\n      <td>अपरिवर्तनशील</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\nwandb.init(project=\"da6401_assignment3_v1\", name=\"attention_vs_vanilla_analysis\")\n\n# Mark which predictions are correct\nvanilla_df[\"VanillaCorrect\"] = vanilla_df[\"Target\"] == vanilla_df[\"Prediction\"]\nattention_df[\"AttentionCorrect\"] = attention_df[\"Target\"] == attention_df[\"Prediction\"]\n\n# Merge the two DataFrames\ncombined = vanilla_df.copy()\ncombined[\"VanillaPrediction\"] = combined[\"Prediction\"]  # rename for clarity\ncombined[\"AttentionPrediction\"] = attention_df[\"Prediction\"]\ncombined[\"AttentionCorrect\"] = attention_df[\"AttentionCorrect\"]\n\n# Filter: incorrect in vanilla but correct in attention\ncorrected_cases = combined[(combined[\"VanillaCorrect\"] == False) & (combined[\"AttentionCorrect\"] == True)]\n\n# Drop the old generic Prediction column if needed\ncorrected_cases = corrected_cases.drop(columns=[\"Prediction\"])\n\n# Create wandb table\ntable = wandb.Table(columns=[\"Source\", \"Target\", \"VanillaPrediction\", \"AttentionPrediction\"])\nfor _, row in corrected_cases.iterrows():\n    table.add_data(row[\"Source\"], row[\"Target\"], row[\"VanillaPrediction\"], row[\"AttentionPrediction\"])\n\n# Log the table to wandb\nwandb.log({\"Corrected_Predictions\": table})\n\n# Finish the run\nwandb.finish()\n\n# Show corrected predictions\nprint(f\"\\nTotal corrections made by attention model: {len(corrected_cases)}\\n\")\ncorrected_cases[[\"Source\", \"Target\", \"VanillaPrediction\", \"AttentionPrediction\"]].head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:07:38.159252Z","iopub.execute_input":"2025-05-21T12:07:38.159554Z","iopub.status.idle":"2025-05-21T12:07:45.443945Z","shell.execute_reply.started":"2025-05-21T12:07:38.159527Z","shell.execute_reply":"2025-05-21T12:07:45.443260Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_120738-a9c38p0h</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/a9c38p0h' target=\"_blank\">attention_vs_vanilla_analysis</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/a9c38p0h' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/a9c38p0h</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">attention_vs_vanilla_analysis</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/a9c38p0h' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/a9c38p0h</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_120738-a9c38p0h/logs</code>"},"metadata":{}},{"name":"stdout","text":"\nTotal corrections made by attention model: 524\n\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"              Source        Target VanillaPrediction AttentionPrediction\n0                ank           अंक               एंक                 अंक\n2              ankit         अंकित              आंकत               अंकित\n7              ankor         अंकोर             एंकोर               अंकोर\n9            angarak        अंगारक             अंगरक              अंगारक\n23           ambaani        अंबानी            अमबानी              अंबानी\n24            ambani        अंबानी            अमबानी              अंबानी\n51             azhar          अजहर              अजार                अजहर\n53             agnat        अज्ञात            अग्ञात              अज्ञात\n59              atke          अटके               अटे                अटके\n68           atharva         अथर्व             अठर्व               अथर्व\n75         advaitwad     अद्वैतवाद        अद्वैत्वाद           अद्वैतवाद\n82       adhyayanrat      अध्ययनरत         अध्ययनर्त            अध्ययनरत\n83        adhyaynrat      अध्ययनरत         अध्ययनर्त            अध्ययनरत\n92       anaavashyak      अनावश्यक         अनावाश्यक            अनावश्यक\n93        anavashyak      अनावश्यक          अनावाशयक            अनावश्यक\n94         anavshyak      अनावश्यक           अनावशयक            अनावश्यक\n95        anawashyak      अनावश्यक          अनावाशयक            अनावश्यक\n101         anukulta      अनुकूलता          अनुकुलता            अनुकूलता\n108           anuthi         अनूठी             अनुठि               अनूठी\n116  aparivartanshil  अपरिवर्तनशील       अपरिवर्तशील        अपरिवर्तनशील","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Target</th>\n      <th>VanillaPrediction</th>\n      <th>AttentionPrediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ank</td>\n      <td>अंक</td>\n      <td>एंक</td>\n      <td>अंक</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ankit</td>\n      <td>अंकित</td>\n      <td>आंकत</td>\n      <td>अंकित</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ankor</td>\n      <td>अंकोर</td>\n      <td>एंकोर</td>\n      <td>अंकोर</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>angarak</td>\n      <td>अंगारक</td>\n      <td>अंगरक</td>\n      <td>अंगारक</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ambaani</td>\n      <td>अंबानी</td>\n      <td>अमबानी</td>\n      <td>अंबानी</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>ambani</td>\n      <td>अंबानी</td>\n      <td>अमबानी</td>\n      <td>अंबानी</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>azhar</td>\n      <td>अजहर</td>\n      <td>अजार</td>\n      <td>अजहर</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>agnat</td>\n      <td>अज्ञात</td>\n      <td>अग्ञात</td>\n      <td>अज्ञात</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>atke</td>\n      <td>अटके</td>\n      <td>अटे</td>\n      <td>अटके</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>atharva</td>\n      <td>अथर्व</td>\n      <td>अठर्व</td>\n      <td>अथर्व</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>advaitwad</td>\n      <td>अद्वैतवाद</td>\n      <td>अद्वैत्वाद</td>\n      <td>अद्वैतवाद</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>adhyayanrat</td>\n      <td>अध्ययनरत</td>\n      <td>अध्ययनर्त</td>\n      <td>अध्ययनरत</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>adhyaynrat</td>\n      <td>अध्ययनरत</td>\n      <td>अध्ययनर्त</td>\n      <td>अध्ययनरत</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>anaavashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाश्यक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>anavashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>anavshyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>anawashyak</td>\n      <td>अनावश्यक</td>\n      <td>अनावाशयक</td>\n      <td>अनावश्यक</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>anukulta</td>\n      <td>अनुकूलता</td>\n      <td>अनुकुलता</td>\n      <td>अनुकूलता</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>anuthi</td>\n      <td>अनूठी</td>\n      <td>अनुठि</td>\n      <td>अनूठी</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>aparivartanshil</td>\n      <td>अपरिवर्तनशील</td>\n      <td>अपरिवर्तशील</td>\n      <td>अपरिवर्तनशील</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"!apt-get install fonts-noto fonts-noto-core fonts-noto-unhinted fonts-noto-ui-core fonts-noto-ui-extra fonts-noto-cjk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:50:33.219668Z","iopub.execute_input":"2025-05-21T12:50:33.220027Z","iopub.status.idle":"2025-05-21T12:50:35.658843Z","shell.execute_reply.started":"2025-05-21T12:50:33.220000Z","shell.execute_reply":"2025-05-21T12:50:35.658074Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nfonts-noto-cjk is already the newest version (1:20220127+repack1-1).\nfonts-noto-cjk set to manually installed.\nfonts-noto-core is already the newest version (20201225-1build1).\nfonts-noto-core set to manually installed.\nfonts-noto-ui-core is already the newest version (20201225-1build1).\nfonts-noto-ui-core set to manually installed.\nfonts-noto is already the newest version (20201225-1build1).\nfonts-noto-ui-extra is already the newest version (20201225-1build1).\nfonts-noto-ui-extra set to manually installed.\nfonts-noto-unhinted is already the newest version (20201225-1build1).\nfonts-noto-unhinted set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nplt.rcParams['font.family'] = [\n    'Lohit Devanagari',\n    'DejaVu Sans',           # Good for Latin\n    'Noto Sans Devanagari',  # Good for Devanagari\n    'Arial Unicode MS',      # Good fallback for both\n    'sans-serif'\n]\nmatplotlib.rcParams['font.family'] = [\n    'Lohit Devanagari'\n    'DejaVu Sans',           # Good for Latin\n    'Noto Sans Devanagari',  # Good for Devanagari\n    'Arial Unicode MS',      # Good fallback for both\n    'sans-serif'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T13:10:18.267512Z","iopub.execute_input":"2025-05-21T13:10:18.268213Z","iopub.status.idle":"2025-05-21T13:10:18.272738Z","shell.execute_reply.started":"2025-05-21T13:10:18.268186Z","shell.execute_reply":"2025-05-21T13:10:18.272046Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# import torch\n# import matplotlib.pyplot as plt\n# import wandb\n# import random\n# import os\n\nwandb.init(project=\"da6401_assignment3_v1\", name=\"attention_heatmaps\", job_type=\"attention_viz\")\n\n# You must define these functions or use your own\ndef decode_sequence(tensor, chr_to_idx, idx_to_char):\n    tokens = []\n    for idx in tensor:\n        idx = idx.item()\n        if idx == 0:  # padding\n            continue\n        tokens.append(idx_to_char.get(idx, '?'))\n    return tokens\n\n# Create a directory to save optional images\nos.makedirs('attention_heatmaps', exist_ok=True)\n\n# Prepare model and device\nmodel.eval()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nattention_images = []\nsampled = 0\nmax_samples = 9\n\nwith torch.no_grad():\n    for batch in data.test_dataloader():\n        src, tgt = batch\n        src, tgt = src.to(device), tgt.to(device)\n        outputs, attention_weights_all = model(src, tgt, teacher_forcing_ratio=0)\n        preds = outputs.argmax(dim=2)\n\n        batch_size = src.size(0)\n        for i in range(batch_size):\n            if sampled >= max_samples:\n                break\n\n            src_tokens = decode_sequence(src[i], data.source_chr_to_idx, data.source_idx_to_char)\n            tgt_tokens = decode_sequence(tgt[i][1:], data.target_chr_to_idx, data.target_idx_to_char)\n\n            attn = attention_weights_all[i].cpu().numpy()[:len(tgt_tokens), :len(src_tokens)]\n\n            fig, ax = plt.subplots(figsize=(6, 4))\n            cax = ax.imshow(attn, cmap='viridis', aspect='auto')\n\n            ax.set_xticks(range(len(src_tokens)))\n            ax.set_yticks(range(len(tgt_tokens)))\n            ax.set_xticklabels(src_tokens, rotation=90)\n            ax.set_yticklabels(tgt_tokens)\n            ax.set_xlabel(\"Source Tokens\")\n            ax.set_ylabel(\"Target Tokens\")\n            ax.set_title(f\"Attention Heatmap {sampled+1}\")\n\n            fig.colorbar(cax, ax=ax)\n            plt.tight_layout()\n\n            attention_images.append(wandb.Image(fig, caption=f\"{''.join(src_tokens)} → {''.join(tgt_tokens)}\"))\n            plt.close()\n            sampled += 1\n\n        if sampled >= max_samples:\n            break\n\n# Log to W&B\nwandb.log({\"Attention Heatmaps (3x3 Grid)\": attention_images})\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T13:10:21.502285Z","iopub.execute_input":"2025-05-21T13:10:21.502579Z","iopub.status.idle":"2025-05-21T13:10:30.088048Z","shell.execute_reply.started":"2025-05-21T13:10:21.502559Z","shell.execute_reply":"2025-05-21T13:10:30.087362Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_131021-8kbg5gc6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/8kbg5gc6' target=\"_blank\">attention_heatmaps</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/8kbg5gc6' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/8kbg5gc6</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Matplotlib currently does not support Devanagari natively.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2700650120.py:60: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n  plt.tight_layout()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">attention_heatmaps</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/8kbg5gc6' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/8kbg5gc6</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 9 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_131021-8kbg5gc6/logs</code>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport wandb\nimport pandas as pd\nimport html  # To handle special characters and ensure proper encoding\nfrom torch.utils.data import DataLoader\n\n# === WandB Init ===\nwandb.init(project=\"da6401_assignment3_v1\", name=\"connectivity_attention\", job_type=\"html_vis\")\nrun_name = wandb.run.name\n\n# === Setup ===\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device).eval()  # Make sure your model variable is defined and loaded\ndatamodule = TrasnliterationDataModule(data_dir=dataset_path)  # Replace path\ndatamodule.prepare_data()\n\n# === Color Map ===\ndef get_shade_color(value):\n    # Modify this function to return colors directly from the value\n    colors = ['#00fa00', '#00f500', '#00eb00', '#00e000', '#00db00',\n              '#00d100', '#00c700', '#00c200', '#00b800', '#00ad00',\n              '#00a800', '#009e00', '#009400', '#008f00', '#008500',\n              '#007500', '#007000', '#006600', '#006100', '#005c00',\n              '#005200', '#004d00', '#004700', '#003d00', '#003800',\n              '#003300', '#002900', '#002400', '#001f00', '#001400']\n    idx = int((value * 100) / 5)\n    return colors[min(max(idx, 0), len(colors)-1)]\n\n# === Decode Sequences ===\ndef decode_sequence(tensor, idx_to_char):\n    return [idx_to_char[idx.item()] for idx in tensor if idx.item() != 0]\n\n# === HTML Builder ===\ndef create_file(text_colors, input_words, output_words, file_path):\n    # Initialize HTML with style\n    html_content = \"<html><head>\"\n    \n    # Adding the CSS for interactivity\n    html_content += \"\"\"\n    <style>\n        body {\n            font-family: 'Devanagari', sans-serif;\n        }\n        .token { cursor: pointer; padding: 5px; margin: 2px; }\n        .highlight { background-color: yellow; }\n        .attention { background-color: lightblue; }\n        .tooltip {\n            visibility: hidden;\n            position: absolute;\n            background-color: black;\n            color: white;\n            text-align: center;\n            border-radius: 5px;\n            padding: 5px;\n            font-size: 12px;\n            z-index: 1;\n        }\n        .token:hover .tooltip {\n            visibility: visible;\n        }\n    </style>\n    \"\"\"\n    \n    # Adding JavaScript for hover interaction\n    html_content += \"\"\"\n    <script>\n        function highlightToken(id) {\n            var token = document.getElementById(id);\n            token.classList.toggle('highlight');\n        }\n\n        function showTooltip(event, value) {\n            var tooltip = document.getElementById('tooltip');\n            tooltip.innerHTML = \"Attention Weight: \" + value.toFixed(2);\n            tooltip.style.left = event.pageX + 5 + \"px\";\n            tooltip.style.top = event.pageY + 5 + \"px\";\n            tooltip.style.visibility = 'visible';\n        }\n\n        function hideTooltip() {\n            var tooltip = document.getElementById('tooltip');\n            tooltip.style.visibility = 'hidden';\n        }\n    </script>\n    \"\"\"\n    \n    html_content += \"</head><body style='font-family: monospace;'>\"\n    \n    # Adding the tooltip element\n    html_content += '<div id=\"tooltip\" class=\"tooltip\"></div>'\n    \n    # Generating the table with highlighted tokens\n    for k in range(len(output_words)):\n        # Escape HTML characters (including Devanagari) to prevent rendering issues\n        input_sentence = ''.join([html.escape(word) for word in input_words[k]])\n        output_sentence = ''.join([html.escape(word) for word in output_words[k]])\n        \n        html_content += f\"<h3>Sample {k+1}: {input_sentence} → {output_sentence}</h3><pre>\"\n        for i in range(len(output_words[k])):\n            html_content += f\"<b>{output_words[k][i]}</b>: \"\n            for j in range(len(input_words[k])):\n                attention_value = text_colors[k][i][j]  # This is already a color string\n                html_content += f\"<span id='src_{k}_{j}' class='token' onmouseover='showTooltip(event, {attention_value})' onmouseout='hideTooltip()' style='background-color:{attention_value};' onclick='highlightToken(\\\"src_{k}_{j}\\\")'>{input_words[k][j]}</span> \"\n            html_content += \"<br>\"\n        html_content += \"</pre><hr>\"\n    \n    html_content += \"</body></html>\"\n    \n    # Saving the HTML file with UTF-8 encoding to handle Devanagari characters\n    out_path = os.path.join(file_path, \"connectivity_interactive.html\")\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(html_content)\n    \n    return out_path\n\n\n# === Inference for One Word ===\ndef run_inference_on_word(src_tensor, model, datamodule):\n    src_tensor = src_tensor.unsqueeze(0).to(device)\n    tgt_dummy = torch.zeros((1, 20), dtype=torch.long).to(device)\n    with torch.no_grad():\n        outputs, att_weights = model(src_tensor, tgt_dummy, teacher_forcing_ratio=0)\n    \n    pred_ids = outputs.argmax(dim=2).squeeze(0)\n    att_weights = att_weights[0].cpu().numpy()[:len(pred_ids), :src_tensor.size(1)]\n\n    src_tokens = decode_sequence(src_tensor[0], datamodule.source_idx_to_char)\n    tgt_tokens = decode_sequence(pred_ids, datamodule.target_idx_to_char)\n\n    return tgt_tokens, src_tokens, att_weights\n\n\n# === Randomly Sample 3 Test Words ===\ntest_set = datamodule.test_dataset\nsamples = random.sample(range(len(test_set)), 3)\n\ninput_words = []\noutput_words = []\ncolor_list = []\n\nfor idx in samples:\n    src_tensor, _ = test_set[idx]  # get source\n    out_toks, in_toks, att = run_inference_on_word(src_tensor, model, datamodule)\n\n    text_colours = [[get_shade_color(att[i][j]) for j in range(len(in_toks))] for i in range(len(out_toks))]\n\n    input_words.append(in_toks)\n    output_words.append(out_toks)\n    color_list.append(text_colours)\n\n# === Save HTML ===\noutput_dir = os.path.join(os.getcwd(), \"predictions_attention\", run_name)\nos.makedirs(output_dir, exist_ok=True)\nhtml_path = create_file(color_list, input_words, output_words, output_dir)\n\n# === Log to W&B ===\nwandb.log({\"custom_file\": wandb.Html(open(html_path))})\n\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T13:58:21.618073Z","iopub.execute_input":"2025-05-21T13:58:21.618580Z","iopub.status.idle":"2025-05-21T13:58:28.814539Z","shell.execute_reply.started":"2025-05-21T13:58:21.618559Z","shell.execute_reply":"2025-05-21T13:58:28.814051Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing previous runs because reinit is set to 'default'."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">connectivity_attention</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd1zx9l6' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd1zx9l6</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_135727-sd1zx9l6/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_135821-x68v1jg1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x68v1jg1' target=\"_blank\">connectivity_attention</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x68v1jg1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x68v1jg1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">connectivity_attention</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x68v1jg1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x68v1jg1</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_135821-x68v1jg1/logs</code>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"import os\nimport torch\nimport wandb\nfrom matplotlib import font_manager as fm\nfrom IPython.display import display, HTML\n\n# Initialize W&B\nwandb.init(project=\"da6401_assignment3_v1\", name=\"attention_connectivity\", job_type=\"attention_html\")\n\n# Decode sequence\ndef decode_sequence(tensor, chr_to_idx, idx_to_char):\n    tokens = []\n    for idx in tensor:\n        idx = idx.item()\n        if idx == 0:\n            continue\n        tokens.append(idx_to_char.get(idx, '?'))\n    return tokens\n\n# Color mapping (dark green = strong attention)\ndef get_shade_color(value):\n    colors = ['#00fa00', '#00f500',  '#00eb00', '#00e000',  '#00db00',  \n              '#00d100',  '#00c700',  '#00c200', '#00b800',  '#00ad00',  \n              '#00a800',  '#009e00',  '#009400', '#008f00',  '#008500',\n              '#007500',  '#007000',  '#006600', '#006100',  '#005c00',  \n              '#005200',  '#004d00',  '#004700', '#003d00',  '#003800',  \n              '#003300',  '#002900',  '#002400',  '#001f00',  '#001400']\n    value = int((value * 100) / 5)\n    value = min(max(value, 0), len(colors) - 1)\n    return colors[value]\n\n# HTML generation\ndef create_file(text_colors, input_word, output_word, file_path=os.getcwd()):\n    html_text = '''<html><body style=\"font-family:monospace;\">'''\n    for k in range(len(output_word)):\n        html_text += f\"<h4>Output {k+1}: {''.join(output_word[k])}</h4>\"\n        html_text += \"<pre style='line-height: 2;'>\"\n        for i in range(len(output_word[k])):\n            html_text += f\"<b>{output_word[k][i]}</b>: \"\n            for j in range(len(input_word[k])):\n                color = text_colors[k][i][j]\n                html_text += f\"<span style='background-color:{color};'>{input_word[k][j]}</span> \"\n            html_text += \"<br>\"\n        html_text += \"</pre><hr>\"\n    html_text += \"</body></html>\"\n\n    fname = os.path.join(file_path, \"connectivity.html\")\n    with open(fname, \"w\", encoding=\"utf-8\") as f:\n        f.write(html_text)\n    return fname\n\n# Inference model (based on your syntax)\ndef inference_model(input_str, rnn_type):\n    model.eval()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Encode input\n    src = torch.tensor([data.encode_source(input_str)], dtype=torch.long).to(device)\n\n    # Dummy target just for passing shape (no teacher forcing)\n    tgt = torch.zeros((1, 20), dtype=torch.long).to(device)  # adjust max_len if needed\n\n    with torch.no_grad():\n        outputs, attention_weights_all = model(src, tgt, teacher_forcing_ratio=0)\n\n    preds = outputs.argmax(dim=2)[0]  # batch size = 1\n    src_tokens = decode_sequence(src[0], data.source_chr_to_idx, data.source_idx_to_char)\n    tgt_tokens = decode_sequence(preds, data.target_chr_to_idx, data.target_idx_to_char)\n    attn = attention_weights_all[0].cpu().numpy()[:len(tgt_tokens), :len(src_tokens)]\n\n    return tgt_tokens, src_tokens, outputs, attn\n\n# Connectivity pipeline\ndef connectivity(input_words, rnn_type, file_path):\n    color_list = []\n    input_word_list = []\n    output_word_list = []\n\n    for word in input_words:\n        output_word, input_word, _, att_w = inference_model(word, rnn_type)\n        text_colours = []\n        for i in range(len(output_word)):\n            row = [get_shade_color(att_w[i][j]) for j in range(len(input_word))]\n            text_colours.append(row)\n        color_list.append(text_colours)\n        input_word_list.append(input_word)\n        output_word_list.append(output_word)\n\n    html_file_path = create_file(color_list, input_word_list, output_word_list, file_path)\n    return html_file_path\n\n# === Run the full pipeline ===\noutput_dir = os.path.join(os.getcwd(), \"predictions_attention\", str(run_name))\nos.makedirs(output_dir, exist_ok=True)\n\ninput_examples = ['anjali', 'underwear', 'agastya']  # Your test samples\nhtml_file = connectivity(input_examples, rnn_type, output_dir)\n\n# === Log HTML file to W&B as artifact ===\nartifact = wandb.Artifact(\"attention_connectivity_html\", type=\"visualization\")\nartifact.add_file(html_file)\nwandb.log_artifact(artifact)\n\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:00:06.307315Z","iopub.execute_input":"2025-05-21T14:00:06.307600Z","iopub.status.idle":"2025-05-21T14:00:13.265016Z","shell.execute_reply.started":"2025-05-21T14:00:06.307580Z","shell.execute_reply":"2025-05-21T14:00:13.264388Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_140006-yv30rpsf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/yv30rpsf' target=\"_blank\">connectivity_attention</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/yv30rpsf' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/yv30rpsf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">connectivity_attention</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/yv30rpsf' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/yv30rpsf</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_140006-yv30rpsf/logs</code>"},"metadata":{}}],"execution_count":58},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"src_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T13:13:57.663219Z","iopub.execute_input":"2025-05-21T13:13:57.663837Z","iopub.status.idle":"2025-05-21T13:13:57.668664Z","shell.execute_reply.started":"2025-05-21T13:13:57.663803Z","shell.execute_reply":"2025-05-21T13:13:57.668097Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'<EOW>': 1,\n '<SOW>': 2,\n '<UNK>': 3,\n 'a': 4,\n 'b': 5,\n 'c': 6,\n 'd': 7,\n 'e': 8,\n 'f': 9,\n 'g': 10,\n 'h': 11,\n 'i': 12,\n 'j': 13,\n 'k': 14,\n 'l': 15,\n 'm': 16,\n 'n': 17,\n 'o': 18,\n 'p': 19,\n 'q': 20,\n 'r': 21,\n 's': 22,\n 't': 23,\n 'u': 24,\n 'v': 25,\n 'w': 26,\n 'x': 27,\n 'y': 28,\n 'z': 29,\n '<PAD>': 0}"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport wandb\nimport pandas as pd\nfrom torch.utils.data import DataLoader\n\n# === WandB Init ===\nwandb.init(project=\"da6401_assignment3_v1\", name=\"connectivity_attention\", job_type=\"html_vis\")\nrun_name = wandb.run.name\n\n# === Setup ===\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device).eval()  # Make sure your model variable is defined and loaded\ndatamodule = TrasnliterationDataModule(data_dir=dataset_path)  # Replace path\ndatamodule.prepare_data()\n\n# === Color Map ===\ndef get_shade_color(value):\n    colors = ['#00fa00', '#00f500', '#00eb00', '#00e000', '#00db00',\n              '#00d100', '#00c700', '#00c200', '#00b800', '#00ad00',\n              '#00a800', '#009e00', '#009400', '#008f00', '#008500',\n              '#007500', '#007000', '#006600', '#006100', '#005c00',\n              '#005200', '#004d00', '#004700', '#003d00', '#003800',\n              '#003300', '#002900', '#002400', '#001f00', '#001400']\n    idx = int((value * 100) / 5)\n    return colors[min(max(idx, 0), len(colors)-1)]\n\n# === Decode Sequences ===\ndef decode_sequence(tensor, idx_to_char):\n    return [idx_to_char[idx.item()] for idx in tensor if idx.item() != 0]\n\n# === HTML Builder ===\ndef create_file(text_colors, input_words, output_words, file_path):\n    html = \"<html><body style='font-family: monospace;'>\"\n    for k in range(len(output_words)):\n        html += f\"<h3>Sample {k+1}: {''.join(input_words[k])} → {''.join(output_words[k])}</h3><pre>\"\n        for i in range(len(output_words[k])):\n            html += f\"<b>{output_words[k][i]}</b>: \"\n            for j in range(len(input_words[k])):\n                html += f\"<span style='background-color:{text_colors[k][i][j]};'>{input_words[k][j]}</span> \"\n            html += \"<br>\"\n        html += \"</pre><hr>\"\n    html += \"</body></html>\"\n    \n    out_path = os.path.join(file_path, \"connectivity.html\")\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(html)\n    return out_path\n\n# === Inference for One Word ===\ndef run_inference_on_word(src_tensor, model, datamodule):\n    src_tensor = src_tensor.unsqueeze(0).to(device)\n    tgt_dummy = torch.zeros((1, 20), dtype=torch.long).to(device)\n    with torch.no_grad():\n        outputs, att_weights = model(src_tensor, tgt_dummy, teacher_forcing_ratio=0)\n    \n    pred_ids = outputs.argmax(dim=2).squeeze(0)\n    att_weights = att_weights[0].cpu().numpy()[:len(pred_ids), :src_tensor.size(1)]\n\n    src_tokens = decode_sequence(src_tensor[0], datamodule.source_idx_to_char)\n    tgt_tokens = decode_sequence(pred_ids, datamodule.target_idx_to_char)\n\n    return tgt_tokens, src_tokens, att_weights\n\n# === Randomly Sample 3 Test Words ===\ntest_set = datamodule.test_dataset\nsamples = random.sample(range(len(test_set)), 3)\n\ninput_words = []\noutput_words = []\ncolor_list = []\n\nfor idx in samples:\n    src_tensor, _ = test_set[idx]  # get source\n    out_toks, in_toks, att = run_inference_on_word(src_tensor, model, datamodule)\n\n    text_colours = [[get_shade_color(att[i][j]) for j in range(len(in_toks))] for i in range(len(out_toks))]\n\n    input_words.append(in_toks)\n    output_words.append(out_toks)\n    color_list.append(text_colours)\n\n# === Save HTML ===\noutput_dir = os.path.join(os.getcwd(), \"predictions_attention\", run_name)\nos.makedirs(output_dir, exist_ok=True)\nhtml_path = create_file(color_list, input_words, output_words, output_dir)\n\n# === Log to W&B ===\n# wandb.log({\"custom_file\": wandb.Html(open(html_path))})\nartifact = wandb.Artifact(\"connectivity_attention_html\", type=\"visualization\")\nartifact.add_file(html_path)\nwandb.log_artifact(artifact)\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:06:31.309294Z","iopub.execute_input":"2025-05-21T14:06:31.310109Z","iopub.status.idle":"2025-05-21T14:06:39.255570Z","shell.execute_reply.started":"2025-05-21T14:06:31.310078Z","shell.execute_reply":"2025-05-21T14:06:39.254850Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_140631-x2t1mofk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x2t1mofk' target=\"_blank\">connectivity_attention</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x2t1mofk' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x2t1mofk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">connectivity_attention</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x2t1mofk' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/x2t1mofk</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_140631-x2t1mofk/logs</code>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"# # import torch\n# # import matplotlib.pyplot as plt\n# # import seaborn as sns\n# # import wandb\n# # import random\n# # import os\n\n# wandb.init(project=\"da6401_assignment3_v1\", name=\"attention_heatmaps\", job_type=\"attention_viz\")\n\n# # You must define these functions or use your own\n# def decode_sequence(tensor, chr_to_idx, idx_to_char):\n#     tokens = []\n#     for idx in tensor:\n#         idx = idx.item()\n#         if idx == 0:  # padding\n#             continue\n#         tokens.append(idx_to_char.get(idx, '?'))\n#     return tokens\n\n# # Create a directory to save optional images\n# os.makedirs('attention_heatmaps', exist_ok=True)\n\n# # Prepare model and device\n# model.eval()\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model.to(device)\n\n# attention_images = []\n# sampled = 0\n# max_samples = 9\n\n# with torch.no_grad():\n#     for batch in data.test_dataloader():\n#         src, tgt = batch\n#         src, tgt = src.to(device), tgt.to(device)\n#         outputs, attention_weights_all = model(src, tgt, teacher_forcing_ratio=0)\n#         preds = outputs.argmax(dim=2)\n\n#         batch_size = src.size(0)\n#         for i in range(batch_size):\n#             if sampled >= max_samples:\n#                 break\n\n#             src_tokens = decode_sequence(src[i], data.source_chr_to_idx, data.source_idx_to_char)\n#             tgt_tokens = decode_sequence(tgt[i][1:], data.target_chr_to_idx, data.target_idx_to_char)\n\n#             attn = attention_weights_all[i].cpu().numpy()[:len(tgt_tokens), :len(src_tokens)]\n\n#             fig, ax = plt.subplots(figsize=(6, 4))\n#             sns.heatmap(attn, xticklabels=src_tokens, yticklabels=tgt_tokens, cmap=\"viridis\", cbar=True, ax=ax)\n#             ax.set_xlabel(\"Source Tokens\")\n#             ax.set_ylabel(\"Target Tokens\")\n#             ax.set_title(f\"Attention Heatmap {sampled+1}\")\n#             plt.tight_layout()\n\n#             attention_images.append(wandb.Image(fig, caption=f\"{''.join(src_tokens)} → {''.join(tgt_tokens)}\"))\n#             plt.close()\n#             sampled += 1\n\n#         if sampled >= max_samples:\n#             break\n\n# # Log to W&B\n# wandb.log({\"Attention Heatmaps (3x3 Grid)\": attention_images})\n# wandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:43:53.133935Z","iopub.execute_input":"2025-05-21T12:43:53.134554Z","iopub.status.idle":"2025-05-21T12:44:01.917720Z","shell.execute_reply.started":"2025-05-21T12:43:53.134532Z","shell.execute_reply":"2025-05-21T12:44:01.917076Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_124353-sd3b239n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd3b239n' target=\"_blank\">attention_heatmaps</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd3b239n' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd3b239n</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Matplotlib currently does not support Devanagari natively.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Matplotlib currently does not support Devanagari natively.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n/usr/local/lib/python3.11/dist-packages/wandb/sdk/data_types/image.py:307: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n  util.ensure_matplotlib_figure(data).savefig(buf, format=self.format)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">attention_heatmaps</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd3b239n' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/sd3b239n</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 9 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_124353-sd3b239n/logs</code>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"# # import torch\n# # import matplotlib.pyplot as plt\n# # import os\n# # import random\n# # import wandb\n# # import matplotlib.font_manager as fm\n# # from io import BytesIO\n# # from PIL import Image\n\n# # # Load Devanagari font\n# # font_path = \"/usr/share/fonts/truetype/noto/NotoSansDevanagari-Regular.ttf\"\n# # if not os.path.exists(font_path):\n# #     import urllib.request\n# #     os.makedirs(os.path.dirname(font_path), exist_ok=True)\n# #     url = \"https://github.com/googlefonts/noto-fonts/blob/main/hinted/ttf/NotoSansDevanagari/NotoSansDevanagari-Regular.ttf?raw=true\"\n# #     urllib.request.urlretrieve(url, font_path)\n\n# # devanagari_font = fm.FontProperties(fname=font_path)\n# # plt.rcParams['font.family'] = devanagari_font.get_name()\n\n# # Initialize wandb\n# wandb.init(project=\"da6401_assignment3_v1\", name=\"attention_heatmaps_plt\", job_type=\"visualization\")\n\n# # Prepare model and data\n# data.prepare_data()\n# test_dataloader = data.test_dataloader()\n# model.eval()\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# model.to(device)\n\n# # Collect 9 attention maps\n# samples_to_plot = []\n# with torch.no_grad():\n#     for batch in test_dataloader:\n#         src, tgt = batch\n#         src, tgt = src.to(device), tgt.to(device)\n#         outputs, attn_weights_all = model(src, tgt, teacher_forcing_ratio=0)\n#         preds = outputs.argmax(dim=2)\n\n#         for i in range(src.size(0)):\n#             if len(samples_to_plot) >= 9:\n#                 break\n\n#             src_str = decode_sequence(src[i], data.source_chr_to_idx, data.source_idx_to_char)\n#             tgt_str = decode_sequence(tgt[i][1:], data.target_chr_to_idx, data.target_idx_to_char)\n#             pred_str = decode_sequence(preds[i], data.target_chr_to_idx, data.target_idx_to_char)\n#             attn_weights = attn_weights_all[i].cpu().numpy()\n\n#             src_tokens = list(src_str)\n#             tgt_tokens = list(pred_str)\n\n#             attn_weights = attn_weights[:len(tgt_tokens), :len(src_tokens)]\n\n#             samples_to_plot.append((src_tokens, tgt_tokens, attn_weights, src_str, tgt_str, pred_str))\n#         if len(samples_to_plot) >= 9:\n#             break\n\n# # Plot using matplotlib\n# fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n# for idx, (src_tokens, tgt_tokens, attn, src_str, tgt_str, pred_str) in enumerate(samples_to_plot):\n#     ax = axes[idx // 3][idx % 3]\n#     im = ax.imshow(attn, aspect='auto', cmap='viridis')\n#     ax.set_xticks(range(len(src_tokens)))\n#     ax.set_yticks(range(len(tgt_tokens)))\n#     ax.set_xticklabels(src_tokens, fontproperties=devanagari_font, rotation=90, fontsize=8)\n#     ax.set_yticklabels(tgt_tokens, fontproperties=devanagari_font, fontsize=8)\n#     ax.set_title(f\"Src: {src_str}\\nTgt: {tgt_str}\\nPred: {pred_str}\", fontproperties=devanagari_font, fontsize=10)\n#     fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n\n# plt.tight_layout()\n\n# # Log to wandb\n# buf = BytesIO()\n# plt.savefig(buf, format='png')\n# buf.seek(0)\n# image = Image.open(buf)\n# wandb.log({\"Attention Heatmaps (3x3 Grid)\": wandb.Image(image)})\n\n# plt.close()\n# wandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T12:42:00.679064Z","iopub.execute_input":"2025-05-21T12:42:00.679881Z","iopub.status.idle":"2025-05-21T12:42:10.284789Z","shell.execute_reply.started":"2025-05-21T12:42:00.679850Z","shell.execute_reply":"2025-05-21T12:42:10.284080Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.11"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_124200-83d56nxq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/83d56nxq' target=\"_blank\">attention_heatmaps_plt</a></strong> to <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/83d56nxq' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/83d56nxq</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 108 (l) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 112 (p) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 97 (a) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 110 (n) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 107 (k) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 69 (E) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 79 (O) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 87 (W) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 83 (S) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 114 (r) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 99 (c) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 84 (T) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 103 (g) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 116 (t) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 80 (P) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 101 (e) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 100 (d) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 105 (i) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 111 (o) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:70: UserWarning: Glyph 104 (h) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 97 (a) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 110 (n) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 107 (k) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 69 (E) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 79 (O) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 87 (W) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 83 (S) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 114 (r) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 99 (c) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 84 (T) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 103 (g) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 116 (t) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 80 (P) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 101 (e) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 100 (d) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 105 (i) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 111 (o) missing from current font.\n  plt.savefig(buf, format='png')\n/tmp/ipykernel_35/2926112535.py:74: UserWarning: Glyph 104 (h) missing from current font.\n  plt.savefig(buf, format='png')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">attention_heatmaps_plt</strong> at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/83d56nxq' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1/runs/83d56nxq</a><br> View project at: <a href='https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1' target=\"_blank\">https://wandb.ai/rohitrk06-indian-institute-of-technology-madras/da6401_assignment3_v1</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_124200-83d56nxq/logs</code>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}